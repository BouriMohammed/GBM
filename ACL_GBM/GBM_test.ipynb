{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from script_numba.reformulate_weights import gates\n",
    "from script_numba.GBM import growth_bounds_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka = 0.6\n",
    "kb = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VV = np.load('./inputs/x_interval.npy')\n",
    "HH = np.load(f'./model/imdb/glove/{ka}_{kb}/h_interval.npy')\n",
    "CC = np.load(f'./model/imdb/glove/{ka}_{kb}/c_interval.npy')\n",
    "\n",
    "model = torch.load(f'./model/imdb/glove/{ka}_{kb}/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig_x = sigmoid(x)\n",
    "    return sig_x * (1 - sig_x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_multiplication(array1, array2):\n",
    "    # Unpack the lower and upper bounds\n",
    "    x1, x2 = array1[..., 0], array1[..., 1]\n",
    "    y1, y2 = array2[..., 0], array2[..., 1]\n",
    "    \n",
    "    # Compute all possible products\n",
    "    values1 = x1 * y1\n",
    "    values2 = x1 * y2\n",
    "    values3 = x2 * y1\n",
    "    values4 = x2 * y2\n",
    "    \n",
    "    # Calculate min and max for each interval using NumPy's efficient min and max functions\n",
    "    interval_min = np.minimum.reduce([values1, values2, values3, values4], axis=0)\n",
    "    interval_max = np.maximum.reduce([values1, values2, values3, values4], axis=0)\n",
    "    \n",
    "    return np.stack((interval_min, interval_max), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CUDA kernel\n",
    "@cuda.jit\n",
    "def float_multiplication_kernel(matrix, interval, result):\n",
    "    i, j = cuda.grid(2)\n",
    "    \n",
    "    if i < result.shape[0] and j < result.shape[1]:\n",
    "        # p = matrix[i, j] * interval[i]\n",
    "        # if matrix[i, j] >= 0:\n",
    "        #     result[i, j] = p\n",
    "        # else:\n",
    "        #     result[i, j] = matrix[i][j] * interval[j][V.shape[1]-1-k]\n",
    "   \n",
    "        for k in range(interval.shape[1]):\n",
    "            if matrix[i][j] >= 0:\n",
    "                result[i, j][k] = matrix[i][j] * interval[i][k]\n",
    "            else:\n",
    "                result[i, j][k] = matrix[i][j] * interval[i][interval.shape[1]-1-k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def float_multiplication_optimized(matrix, interval):\n",
    "    # Move data to device\n",
    "    matrix_dev = cuda.to_device(matrix)\n",
    "    interval_dev = cuda.to_device(interval) \n",
    "    result_dev = cuda.device_array((matrix.shape[0], matrix.shape[1],2), dtype=np.float32) \n",
    "\n",
    "    # Define grid and block sizes\n",
    "    threads_per_block = (16, 16)  # Define appropriate block size\n",
    "    blocks_per_grid_x = (matrix.shape[0] + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    blocks_per_grid_y = (matrix.shape[1] + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "    # Launch the kernel\n",
    "    float_multiplication_kernel[blocks_per_grid, threads_per_block](matrix_dev, interval_dev, result_dev)\n",
    "\n",
    "    # Copy the result back to the host\n",
    "    result = result_dev.copy_to_host()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C2_t(V,H,C):\n",
    "    \n",
    "    f = sigmoid(np.dot(forget_gate[0][0],V) + np.dot(forget_gate[0][1],H) + forget_gate[1])\n",
    "    I = sigmoid(np.dot(input_gate[0][0],V) + np.dot(input_gate[0][1],H) + input_gate[1])\n",
    "    g = np.tanh(np.dot(cell_gate[0][0],V) + np.dot(cell_gate[0][1],H) + cell_gate[1])\n",
    "    \n",
    "    return np.multiply(f,C) + np.multiply(I,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposition_2(fct,interval):\n",
    "    result=[]\n",
    "    for i in range (interval.shape[0]):\n",
    "        a = interval[i][0]\n",
    "        b = interval[i][1]\n",
    "        min_fct = np.min([fct(a), fct(b)])\n",
    "        if a<=0 and b >=0:\n",
    "            max_fct = fct(0)\n",
    "        else:\n",
    "            max_fct = np.max([fct(a), fct(b)])\n",
    "        result.append([min_fct,max_fct])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def proposition_4_kernel(omega, U, V, H, bias, T):\n",
    "    i = cuda.grid(1)\n",
    "    max_omega_cols = 300  # Use the maximum possible size for omega columns\n",
    "    max_U_cols = 64       # Use the maximum possible size for U columns \n",
    "    if i < omega.shape[0]:\n",
    "        V_gate_i = cuda.local.array((max_omega_cols, 2), dtype=float32)\n",
    "        H_gate_i = cuda.local.array((max_U_cols, 2), dtype=float32) \n",
    "        \n",
    "        # Compute V_gate_i\n",
    "        for j in range(omega.shape[1]):\n",
    "            for k in range(V.shape[1]):\n",
    "                if omega[i][j] >= 0:\n",
    "                    V_gate_i[j][k] = omega[i][j] * V[j][k]\n",
    "                else:\n",
    "                    V_gate_i[j][k] = omega[i][j] * V[j][V.shape[1]-1-k]\n",
    "        \n",
    "        # Compute H_gate_i\n",
    "        for l in range(U.shape[1]):\n",
    "            for k in range(H.shape[1]):\n",
    "                if U[i][l] >= 0:\n",
    "                    H_gate_i[l][k] = U[i][l] * H[l][k]\n",
    "                else:\n",
    "                    H_gate_i[l][k] = U[i][l] * H[l][H.shape[1]-1-k]\n",
    "        \n",
    "        # Sum V_gate_i and H_gate_i\n",
    "        sum_V = cuda.local.array(2, dtype=float32)\n",
    "        sum_H = cuda.local.array(2, dtype=float32)\n",
    "        for k in range(2):\n",
    "            sum_V[k] = 0.0\n",
    "            sum_H[k] = 0.0\n",
    "        \n",
    "        for j in range(omega.shape[1]):\n",
    "            for k in range(V.shape[1]):\n",
    "                sum_V[k] += V_gate_i[j][k]\n",
    "                \n",
    "        for l in range(U.shape[1]):\n",
    "            for k in range(H.shape[1]):\n",
    "                sum_H[k] += H_gate_i[l][k]\n",
    "        \n",
    "        for k in range(T.shape[1]):\n",
    "            T[i][k] = sum_V[k] + sum_H[k] + bias[i]\n",
    "\n",
    "\n",
    "def proposition_4_optimized(output_gate_0_0, output_gate_0_1, VV, HH, output_gate_1):\n",
    "    # Move data to device\n",
    "    omega_dev = cuda.to_device(output_gate_0_0)\n",
    "    U_dev = cuda.to_device(output_gate_0_1)\n",
    "    V_dev = cuda.to_device(VV)\n",
    "    H_dev = cuda.to_device(HH)\n",
    "    bias_dev = cuda.to_device(output_gate_1)\n",
    "    T_dev = cuda.device_array((omega_dev.shape[0], 2), dtype=np.float32) \n",
    "    \n",
    "    # Define grid and block sizes\n",
    "    threads_per_block = 32\n",
    "    blocks_per_grid = (64 + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    # Launch the kernel\n",
    "    proposition_4_kernel[blocks_per_grid, threads_per_block](omega_dev, U_dev, V_dev, H_dev, bias_dev, T_dev)\n",
    "\n",
    "    # Copy the result back to the host\n",
    "    T = T_dev.copy_to_host()\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposition_5(ct,V,H,C,A,B,D):\n",
    "    under_V = V[:,0]\n",
    "    bar_V = V[:,1]\n",
    "    \n",
    "    under_H = H[:,0]\n",
    "    bar_H = H[:,1]\n",
    "    \n",
    "    under_C = C[:,0]\n",
    "    bar_C = C[:,1]\n",
    "    \n",
    "    mid_V = (under_V + bar_V)/2\n",
    "    mid_H = (under_H + bar_H)/2\n",
    "    mid_C = (under_C + bar_C)/2\n",
    "    \n",
    "    diff_V = bar_V - under_V\n",
    "    diff_H = bar_H - under_H\n",
    "    diff_C = bar_C - under_C\n",
    "\n",
    "    c = []\n",
    "    Ct = ct(mid_V,mid_H,mid_C)\n",
    " \n",
    "    for i in range(C.shape[0]):\n",
    "        min_ci = Ct[i] - np.dot(A[i], diff_V) - np.dot(B[i], diff_H) - np.dot(D[i], diff_C)\n",
    "        max_ci = Ct[i] + np.dot(A[i], diff_V) + np.dot(B[i], diff_H) + np.dot(D[i], diff_C)\n",
    "        c.append([min_ci, max_ci])\n",
    "    return np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM(BM):\n",
    "    return np.max(np.abs(BM), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_o = proposition_4_optimized(output_gate[0][0], output_gate[0][1], VV, HH, output_gate[1])\n",
    "T_f = proposition_4_optimized(forget_gate[0][0], forget_gate[0][1], VV, HH, forget_gate[1])\n",
    "T_I = proposition_4_optimized(input_gate[0][0], input_gate[0][1], VV, HH, input_gate[1])\n",
    "T_g = proposition_4_optimized(cell_gate[0][0], cell_gate[0][1], VV, HH, cell_gate[1])\n",
    "\n",
    "sigma_Tf = sigmoid(T_f)\n",
    "sigma_TI = sigmoid(T_I)\n",
    "sigma_To = sigmoid(T_o)\n",
    "tanh_Tg = np.tanh(T_g)\n",
    "\n",
    "# ct = C_t(T_f, T_I, T_g, CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding $C_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$\\frac{\\partial c_t}{\\partial v_{wt}} \\quad , \\quad \\frac{\\partial c_t}{\\partial h_{t-1}} \\quad and \\quad \\frac{\\partial c_t}{\\partial c_{t-1}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccobian_C(variable):\n",
    "    if variable == 'v':\n",
    "        var = 0\n",
    "    elif variable == 'h':\n",
    "        var = 1\n",
    "    elif variable == 'c':\n",
    "        T1 = sigma_Tf.copy()\n",
    "        T2 = T1[np.newaxis,:,:]\n",
    "        return np.repeat(T2, 64, axis=0)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    T11 = interval_multiplication(proposition_2(sigmoid_derivative, T_f), CC)\n",
    "    T1 = float_multiplication_optimized(forget_gate[0][var], T11)\n",
    "    # T1 = float_multiplication(forget_gate[0][var], T11)\n",
    "\n",
    "    T21 = interval_multiplication(proposition_2(sigmoid_derivative, T_I), tanh_Tg)\n",
    "    T2 = float_multiplication_optimized(input_gate[0][var], T21)\n",
    "    # T2 = float_multiplication(input_gate[0][var], T21)\n",
    "\n",
    "    T31 = interval_multiplication(proposition_2(tanh_derivative, T_g), sigma_TI)\n",
    "    T3 = float_multiplication_optimized(cell_gate[0][var], T31)\n",
    "    # T3 = float_multiplication(cell_gate[0][var], T31)\n",
    "\n",
    "    return T1 + T2 + T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_v = jaccobian_C('v')\n",
    "C_h = jaccobian_C('h')\n",
    "C_c = jaccobian_C('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ac = GBM(C_v)\n",
    "Bc = GBM(C_h)\n",
    "Dc = GBM(C_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding $H_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$\\frac{\\partial h_t}{\\partial v_{wt}} \\quad , \\quad \\frac{\\partial h_t}{\\partial h_{t-1}}\\quad and \\quad \\frac{\\partial h_t}{\\partial c_{t-1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccobian_H(variable):\n",
    "    if variable == 'v':\n",
    "        var = 0\n",
    "        var2 = C_v\n",
    "    elif variable == 'h':\n",
    "        var = 1\n",
    "        var2 = C_h\n",
    "    elif variable == 'c':\n",
    "        T1 = interval_multiplication(interval_multiplication(sigma_To, sigma_Tf), proposition_2(tanh_derivative,proposition_5(C2_t,VV,HH,CC,Ac,Bc,Dc)))\n",
    "        T2 = T1[np.newaxis,:,:]\n",
    "        return np.repeat(T2, 64, axis=0)\n",
    "    else:\n",
    "        return -1\n",
    " \n",
    "    c = proposition_5(C2_t,VV,HH,CC,Ac,Bc,Dc)\n",
    "    T11 = interval_multiplication(proposition_2(sigmoid_derivative, T_o), np.tanh(c))\n",
    "    T1 = float_multiplication_optimized(output_gate[0][var], T11)\n",
    "\n",
    "    T21 = interval_multiplication(proposition_2(tanh_derivative, c), sigma_To)\n",
    "    T22 = T21.copy()\n",
    "    T23 = T22[:,np.newaxis,:]\n",
    "    T2 = interval_multiplication(var2, np.repeat(T23, output_gate[0][var][1].shape, axis=1))\n",
    "    \n",
    "    return T1 + T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_v = jaccobian_H('v')\n",
    "H_h = jaccobian_H('h')\n",
    "H_c = jaccobian_H('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GBM(H_v)\n",
    "B = GBM(H_h)\n",
    "D = GBM(H_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [model[param].cpu().detach().numpy() for param in ['lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0']]\n",
    "weights_reverse = [model[param].cpu().detach().numpy() for param in ['lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,D = growth_bounds_matrix(weights, VV,HH[0],CC[0],64)\n",
    "A_r,B_r,D_r = growth_bounds_matrix(weights_reverse, VV,HH[1],CC[1],64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.814072960924685"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(A, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095.250707646067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(A_r, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33880039991572386"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(B, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406.81301927801786"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(B_r, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16561210155487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.466596215963364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(D_r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.full((64,2),[np.min(HH[0]),np.max(HH[0])])\n",
    "c = np.full((64,2),[np.min(CC[0]),np.max(CC[0])])\n",
    "x = np.full((300,2),[np.min(VV), np.max(VV)] )\n",
    "\n",
    "h1 = np.full((64,2),[np.min(HH[1]),np.max(HH[1])])\n",
    "c1 = np.full((64,2),[np.min(CC[1]),np.max(CC[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1,B_1,D_1 = growth_bounds_matrix(weights, x,h,c,64)\n",
    "A_1_r,B_1_r,D_1_r = growth_bounds_matrix(weights_reverse, x,h1,c1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.776769574047858"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(A_1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176.2027931560228"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(A_1_r, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08150408580265399"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(B_1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458.3771369474824"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(B_1_r, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.38121145963669"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(D_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.91715118288994"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(D_1_r[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
